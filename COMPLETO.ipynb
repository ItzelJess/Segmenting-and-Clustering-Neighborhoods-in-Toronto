{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import numpy as np # library to handle data in a vectorized manner\n\nimport pandas as pd # library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json # library to handle JSON files\n\n!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\nimport folium # map rendering library\n\nprint('Libraries imported.')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import requests\nwebsite_url = requests.get('https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M').text\n!pip install BeautifulSoup4\nfrom bs4 import BeautifulSoup\nsoup = BeautifulSoup(website_url,'html.parser')\n#print(soup.prettify())"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "table1 = soup.find('table',{'class':'wikitable sortable'})\ntable1\n#This also works:\n#table = soup.table.text\n#print(table)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print(table1.tr.text)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "header=[\"PostalCode\",\"Borough\",\"Neighborhood\"]\n\ndf = pd.DataFrame(columns=header)\ndf"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "table1_rows = table1.find_all('tr')\n\nfor tr in table1_rows:\n    td = tr.find_all('td')\n    row = [i.text for i in td]\n    print(row)\n    if row!=[]: #first row is empty. This could be done better\n        postcode = row[0]\n        borough = row[1]\n        neighborhood = row[2]\n    \n        df = df.append({'PostalCode': postcode,\n                                          'Borough': borough,\n                                          'Neighborhood': neighborhood}, ignore_index=True)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We need to clean this up now. We will delete the rows where the borough is not assigned."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df.drop(df[df.Borough.str.contains('Not assigned')].index, inplace = True)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df.reset_index(inplace=True,drop=True)\ndf"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now let's remove the new line tags: \"\\n\""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df = df.replace('\\n','', regex=True)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df['Neighborhood'] = df['Neighborhood'].replace(' /',',', regex=True)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "QUESTION 2\nThe assignment notes that the Geocoder package is unreliable at times, so the csv file with postal codes is provided in the link below."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\ndf_codes = pd.read_csv('https://cocl.us/Geospatial_data')\ndf_codes.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_codes.rename(columns={\"Postal Code\": \"PostalCode\"}, inplace = True) #We will rename the first column to match our original dataframe"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\ndf1 = pd.merge(df, df_codes[['PostalCode','Latitude','Longitude']], on='PostalCode') #Let's now merge both data frames"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\ndf1 #final data frame for question 2"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\nQuestion 3\nIn this section we'll explore and cluster the neighborhoods in Toronto.\nFirst we use Folium to map Toronto."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# create map of Toronto using latitude and longitude values\nlatitude = 43.651070\nlongitude = -79.347015\nmap_toronto = folium.Map(location=[latitude, longitude], zoom_start=10)\n\n# add markers to map\nfor lat, lng, borough, neighborhood in zip(df1['Latitude'], df1['Longitude'], df1['Borough'], df1['Neighborhood']):\n    label = '{}, {}'.format(neighborhood, borough)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_toronto)  \n    \nmap_toronto"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Enter your API credentials to access the Foursquare API."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "CLIENT_ID = 'yourid' # your Foursquare ID\nCLIENT_SECRET = 'yoursecret' # your Foursquare Secret\nVERSION = '20180605' # Foursquare API version\nLIMIT = 100"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The following function will make requests to the API for all the neighborhoods in our dataframe."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "So, let's run the function."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "tor_venues = getNearbyVenues(names=df1['Neighborhood'],\n                                   latitudes=df1['Latitude'],\n                                   longitudes=df1['Longitude']\n                                  )"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print(tor_venues.shape)\ntor_venues.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We have the dataframe above with the different Venues (last column!) for each Neighborhood. How many venues we have for each neighborhood?"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "tor_venues.groupby('Neighborhood').count()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print('There are {} uniques categories.'.format(len(tor_venues['Venue Category'].unique())))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Here we start our analysis of each neighborhood and prepare to cluster them.\nFirst step is to turn the venue categories into dummy variables."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# one hot encoding\ntor_onehot = pd.get_dummies(tor_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# add neighborhood column back to dataframe\ntor_onehot['Neighborhood'] = tor_venues['Neighborhood'] \n\n# move neighborhood column to the first column\nfixed_columns = [tor_onehot.columns[-1]] + list(tor_onehot.columns[:-1])\ntor_onehot = tor_onehot[fixed_columns]\n\ntor_onehot.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\nWe can group the df by neighborhood and find the mean occurrence of venues per neighborhood"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "tor_grouped = tor_onehot.groupby('Neighborhood').mean().reset_index()\ntor_grouped"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "tor_grouped.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let's check the top 5 venues for each neighborhood."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "num_top_venues = 5\n\nfor hood in tor_grouped['Neighborhood']:\n    print(\"----\"+hood+\"----\")\n    temp = tor_grouped[tor_grouped['Neighborhood'] == hood].T.reset_index()\n    temp.columns = ['venue','freq']\n    temp = temp.iloc[1:]\n    temp['freq'] = temp['freq'].astype(float)\n    temp = temp.round({'freq': 2})\n    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n    print('\\n')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "This function will sort the venues in descending order."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now we create a new dataframe with the 10 most common venues per neighborhood."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "num_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighborhood']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Neighborhood'] = tor_grouped['Neighborhood']\n\nfor ind in np.arange(tor_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(tor_grouped.iloc[ind, :], num_top_venues)\n\nneighborhoods_venues_sorted.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We can cluster these neighborhoods based on the similarity of the venues in each of them.\nWe are applying k-means here, with 5 clusters."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# set number of clusters\nkclusters = 5\n\ntor_grouped_clustering = tor_grouped.drop('Neighborhood', 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(tor_grouped_clustering)\n\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:10]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let's merge the previous dataframe with the new cluster labels."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# add clustering labels\nneighborhoods_venues_sorted.insert(0, 'Cluster_Labels', kmeans.labels_)\n\ntor_merged = df1\n\n# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\ntor_merged = tor_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n\ntor_merged.head() # check the last columns!"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "There are some NAs in the dataframe, we will drop these. Plus the clusters are in float. Let's change to integer."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "tor_merged=tor_merged.dropna()\ntor_merged['Cluster_Labels'] = tor_merged.Cluster_Labels.astype(int)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let's map Toronto once again, but with the clusters represented by different colors."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# create map\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(tor_merged['Latitude'], tor_merged['Longitude'], tor_merged['Neighborhood'], tor_merged['Cluster_Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "With the following code, we can explore a specific cluster."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "tor_merged.loc[tor_merged['Cluster_Labels'] == 0, tor_merged.columns[[2] + list(range(5, tor_merged.shape[1]))]]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}